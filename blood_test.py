# -*- coding: utf-8 -*-
"""Blood_Test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rFG_ObcTiio1Zls8oP-CrbDoEKOvwaWy
"""

!pip install kaggle
!pip install tensorflow
!pip install keras

!pip install --upgrade tensorflow

import os
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import torch
import torchvision
import torchvision.transforms as transforms
import keras
from torch.utils.data import DataLoader, Dataset, random_split
from torchvision.datasets import ImageFolder
from torchvision.utils import make_grid
from PIL import Image

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D

from keras.callbacks import LearningRateScheduler, TensorBoard, EarlyStopping
from keras.optimizers import Adam
from keras.losses import SparseCategoricalCrossentropy
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

"""To connect with kaggle, go to kaggle and then go to setting. Scroll down and go to api. Then click on create a new token"""

from google.colab import files
uploaded = files.upload()
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json


!kaggle datasets download -d mohammadamireshraghi/blood-cell-cancer-all-4class
!unzip blood-cell-cancer-all-4class.zip

benign_dir = "./Blood cell Cancer [ALL]/Benign"
malignant_pre_b_dir = "./Blood cell Cancer [ALL]/[Malignant] Pre-B"
malignant_pro_b_dir = "./Blood cell Cancer [ALL]/[Malignant] Pro-B"
malignant_early_pre_b_dir = "./Blood cell Cancer [ALL]/[Malignant] early Pre-B"

directories = [benign_dir, malignant_pre_b_dir, malignant_pro_b_dir, malignant_early_pre_b_dir]
class_labels = ['Benign', 'Malignant_Pre-B', 'Malignant_Pro-B', 'Malignant_early Pre-B']
file_paths = []
labels = []

for directory, label in zip(directories, class_labels):
    files = os.listdir(directory)
    file_paths.extend([os.path.join(directory, file) for file in files])
    labels.extend([label] * len(files))
data = {'file_path': file_paths, 'label': labels}
blood_cell_df = pd.DataFrame(data)

# Handling Missing Values (Fault and Solution)
# Example code to handle missing values (assuming deletion of rows with missing/corrupted images)
# This is just a conceptual example, you may need to adapt it based on your specific dataset structure

# import os

# def load_image(image_path):
#     try:
#         image = mpimg.imread(image_path)
#         return image
#     except:
#         print(f"Error loading image: {image_path}")
#         return None

# # Load and preprocess images, handling missing/corrupted images
# file_paths = [os.path.join(directory, file) for directory in directories for file in os.listdir(directory)]
# images = [load_image(image_path) for image_path in file_paths if load_image(image_path) is not None]

# # Encoding Categorical Labels (Solution)
# # Example code for encoding categorical labels
# from sklearn.preprocessing import LabelEncoder

# label_encoder = LabelEncoder()
# blood_cell_df['encoded_label'] = label_encoder.fit_transform(blood_cell_df['label'])

def display_samples(df, num_samples=5):
    sample_indices = random.sample(range(len(df)), num_samples)
    plt.figure(figsize=(15, 5))
    for i, idx in enumerate(sample_indices):
        img_path = df.loc[idx, 'file_path']
        label = df.loc[idx, 'label']
        img = mpimg.imread(img_path)
        plt.subplot(1, num_samples, i + 1)
        plt.imshow(img)
        plt.title(label)
        plt.axis('off')
    plt.show()

display_samples(blood_cell_df)

train_images, test_images = train_test_split(blood_cell_df, test_size=0.3, random_state=42)
train_set, val_set = train_test_split(blood_cell_df, test_size=0.2, random_state=42)

print("Train set shape:", train_set.shape)
print("Test set shape:", test_images.shape)
print("Validation set shape:", val_set.shape)

transform = transforms.Compose([
    transforms.Resize((64, 64)),  # Resize to 64x64
    transforms.ToTensor(),  # Convert to tensor from pytorch
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize
])

# Create PyTorch dataset
dataset = ImageFolder(root="./Blood cell Cancer [ALL]", transform=transform)

train_size = int(0.7 * len(dataset))
test_size = int(0.15 * len(dataset))
val_size = len(dataset) - train_size - test_size
train_set, test_set, val_set = random_split(dataset, [train_size, test_size, val_size])

batch_size = 8

train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_set, batch_size=batch_size)
val_loader = DataLoader(val_set, batch_size=batch_size)

def show_images(loader, class_labels):
    images, labels = next(iter(loader))
    fig, ax = plt.subplots(figsize=(12, 8))
    ax.set_xticks([]); ax.set_yticks([])
    ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))
    ax.set_title([class_labels[label] for label in labels])

show_images(train_loader, class_labels)
plt.show()

def convert_to_tensorflow_dataset(data_loader):
    images = []
    labels = []
    for batch_images, batch_labels in data_loader:
        images.append(batch_images.numpy())
        labels.append(batch_labels.numpy())
    images = np.concatenate(images)
    labels = np.concatenate(labels)
    dataset = tf.data.Dataset.from_tensor_slices((images, labels))
    return dataset

train_dataset = convert_to_tensorflow_dataset(train_loader)
val_dataset = convert_to_tensorflow_dataset(val_loader)
test_dataset = convert_to_tensorflow_dataset(test_loader)

batch_size = 8

train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size)
val_dataset = val_dataset.batch(batch_size)
test_dataset = test_dataset.batch(batch_size)

for images, labels in train_dataset.take(1):
    print(images.shape)
    print(labels.shape)

def convert_to_tensorflow_dataset(data_loader):
    images = []
    labels = []
    for batch_images, batch_labels in data_loader:
        batch_images = np.transpose(batch_images.numpy(), (0, 2, 3, 1))
        images.append(batch_images)
        labels.append(batch_labels.numpy())
    images = np.concatenate(images)
    labels = np.concatenate(labels)
    dataset = tf.data.Dataset.from_tensor_slices((images, labels))
    return dataset



train_dataset = convert_to_tensorflow_dataset(train_loader)
val_dataset = convert_to_tensorflow_dataset(val_loader)
test_dataset = convert_to_tensorflow_dataset(test_loader)


batch_size = 8


train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size)
val_dataset = val_dataset.batch(batch_size)
test_dataset = test_dataset.batch(batch_size)


model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, kernel_size=(3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])


callbacks = [
    EarlyStopping(patience=3),
    TensorBoard(log_dir='./logs')
]

history = model.fit(train_dataset,
                    epochs=20,
                    validation_data=val_dataset,
                    callbacks=callbacks)
test_loss, test_acc = model.evaluate(test_dataset)
print('Test accuracy:', test_acc)

import os
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import torch
import torchvision.transforms as transforms
import tensorflow as tf
#from tensorflow.keras.preprocessing.image import ImageDataGenerator
from torch.utils.data import DataLoader, Dataset, random_split
from torchvision.datasets import ImageFolder
from torchvision.utils import make_grid

benign_dir = "./Blood cell Cancer [ALL]/Benign"
malignant_pre_b_dir = "./Blood cell Cancer [ALL]/[Malignant] Pre-B"
malignant_pro_b_dir = "./Blood cell Cancer [ALL]/[Malignant] Pro-B"
malignant_early_pre_b_dir = "./Blood cell Cancer [ALL]/[Malignant] early Pre-B"

directories = [benign_dir, malignant_pre_b_dir, malignant_pro_b_dir, malignant_early_pre_b_dir]
class_labels = ['Benign', 'Malignant_Pre-B', 'Malignant_Pro-B', 'Malignant_early Pre-B']
file_paths = []
labels = []
for directory, label in zip(directories, class_labels):
    files = os.listdir(directory)
    file_paths.extend([os.path.join(directory, file) for file in files])
    labels.extend([label] * len(files))


data = {'file_path': file_paths, 'label': labels}
blood_cell_df = pd.DataFrame(data)

def display_samples(df, num_samples=5):
    sample_indices = random.sample(range(len(df)), num_samples)
    plt.figure(figsize=(15, 5))
    for i, idx in enumerate(sample_indices):
        img_path = df.loc[idx, 'file_path']
        label = df.loc[idx, 'label']
        img = mpimg.imread(img_path)
        plt.subplot(1, num_samples, i + 1)
        plt.imshow(img)
        plt.title(label)
        plt.axis('off')
    plt.show()

display_samples(blood_cell_df)

#transformations for preprocessing
transform = transforms.Compose([
    transforms.Resize((64, 64)),  # Resize to 64x64
    transforms.ToTensor(),  # Convert to tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


dataset = ImageFolder(root="./Blood cell Cancer [ALL]", transform=transform)

train_size = int(0.7 * len(dataset))
test_size = int(0.15 * len(dataset))
val_size = len(dataset) - train_size - test_size
train_set, test_set, val_set = random_split(dataset, [train_size, test_size, val_size])

batch_size = 8

def convert_to_tensorflow_dataset(data_loader):
    images = []
    labels = []
    for batch_images, batch_labels in data_loader:
        batch_images = np.transpose(batch_images.numpy(), (0, 2, 3, 1))
        images.append(batch_images)
        labels.append(batch_labels.numpy())
    images = np.concatenate(images)
    labels = np.concatenate(labels)
    dataset = tf.data.Dataset.from_tensor_slices((images, labels))
    return dataset

train_dataset = convert_to_tensorflow_dataset(DataLoader(train_set, batch_size=batch_size, shuffle=True))
val_dataset = convert_to_tensorflow_dataset(DataLoader(val_set, batch_size=batch_size))
test_dataset = convert_to_tensorflow_dataset(DataLoader(test_set, batch_size=batch_size))

def show_images(loader, class_labels):
    images, labels = next(iter(loader))
    fig, ax = plt.subplots(figsize=(12, 8))
    ax.set_xticks([]); ax.set_yticks([])
    ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))
    ax.set_title([class_labels[label] for label in labels])

show_images(train_loader, class_labels)
plt.show()

import os
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, random_split
from torchvision.datasets import ImageFolder
from PIL import Image

import torch.nn as nn
import torch.optim as optim
import torchvision.models as models

transform = transforms.Compose([
    transforms.Resize((64, 64)),  # Resize to 64x64
    transforms.ToTensor(),  # Convert to tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize
])

pytorch_dataset = ImageFolder(root="./Blood cell Cancer [ALL]", transform=transform)

train_size = int(0.7 * len(pytorch_dataset))
test_size = int(0.15 * len(pytorch_dataset))
val_size = len(pytorch_dataset) - train_size - test_size
train_set, test_set, val_set = random_split(pytorch_dataset, [train_size, test_size, val_size])

train_loader = DataLoader(train_set, batch_size=32, shuffle=True)
test_loader = DataLoader(test_set, batch_size=32, shuffle=False)
val_loader = DataLoader(val_set, batch_size=32, shuffle=False)

class ResNetModel(nn.Module):
    def __init__(self):
        super(ResNetModel, self).__init__()
        self.base_model = models.resnet18(pretrained=True)
        num_ftrs = self.base_model.fc.in_features
        self.base_model.fc = nn.Linear(num_ftrs, 4)

    def forward(self, x):
        return self.base_model(x)


resnet_model = ResNetModel()

criterion = nn.CrossEntropyLoss()
resnet_optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)


epochs = 10
for epoch in range(epochs):
    resnet_model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        resnet_optimizer.zero_grad()
        outputs = resnet_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        resnet_optimizer.step()
        running_loss += loss.item()
    print(f"ResNet - Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader)}")


def evaluate_model(model, loader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in loader:
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    return accuracy


resnet_accuracy = evaluate_model(resnet_model, test_loader)
print(f"ResNet Test Accuracy: {resnet_accuracy}%")

class DenseNetModel(nn.Module):
    def __init__(self):
        super(DenseNetModel, self).__init__()
        self.base_model = models.densenet121(pretrained=True)
        num_ftrs = self.base_model.classifier.in_features
        self.base_model.classifier = nn.Linear(num_ftrs, 4)

    def forward(self, x):
        return self.base_model(x)

densenet_model = DenseNetModel()

criterion = nn.CrossEntropyLoss()
densenet_optimizer = optim.Adam(densenet_model.parameters(), lr=0.001)

epochs = 10
for epoch in range(epochs):
    densenet_model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        densenet_optimizer.zero_grad()
        outputs = densenet_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        densenet_optimizer.step()
        running_loss += loss.item()
    print(f"DenseNet - Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader)}")

densenet_accuracy = evaluate_model(densenet_model, test_loader)
print(f"DenseNet Test Accuracy: {densenet_accuracy}%")